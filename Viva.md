These are few questions which we normally ask in DBMI.

**What is data mining ?**

Data Mining is a computational process of discovering patterns in large data sets involving methods at the intersection of artificial intelligence, machine learning, statistics and database system.
Or it can be defined as 
Data mining is a process of discovering interesting patterns from huge amounts of data.


Is data mining a hype ?

**What is Machine Learning ?**

It is subfield of comuter science that focuses on getting computer to act without being explicitly programmed.It focuses on the development of computer program that can change when exposed to new data.

**What is data preprocessing ?**

Data preprocessing is a data mining technique that involves transforming raw data into an understandable format. Real-world data is often incomplete, inconsistent, and/or lacking in certain behaviors or trends, and is likely to contain many errors. Data preprocessing is a proven method of resolving such issues.
Why we need to to preprocess the data ?
Real-world data is often incomplete, inconsistent, and/or lacking in certain behaviors or trends, and is likely to contain many errors. Data preprocessing is a proven method of resolving such issues.

**What is consequence of having a data outliers ?**

An outliers is a value that is very different from the other data in your data set.This can skew your results.

**What is outlier ?**

An outliers is a data object in a data set that deviates significantly from the rest of the data object, as if it were generated by a different mechanism

**What are different methods of detecting outliers ?**

Univariate method: This method looks for data points with extreme values on one variable.
Multivariate method: Here we look for unusual combinations on all the variables.
Minkowski error: This method reduces the contribution of potential outliers in the training process.
Are their any applications detecting of outliers ?

**What is data exploration ?**

Data exploration is the first step in data analysis and typically involves summarizing the main characteristics of a dataset. It is commonly conducted using visual analytics tools, but can also be done in more advanced statistical software, such as R.

Can you draw box plot of given data ?

What is five number summary ?
The five-number summary is a set of descriptive statistics that provide information about a dataset. It consists of the five most important sample percentiles: the sample minimum (smallest observation) the lower quartile or first quartile,mean,third quartile and maximum.
What are the data mining applications ?

Can you explain how data mining is used in droid detection ?

Explain data mining applications for the finance ?

Explain data mining application for CRM ?

Explain how data mining can be used in medical industry ?

**Explain data preprocessing steps ?**
. Data Cleaning: Clean the data by filling in missing values, smoothening noisy data, identifying and
removing outliers and inconsistencies.
b. Data Integration: Data analysis involves integrating multiple databases, data cubes or files to
obtain consolidated data. Before any data is used, integration problems such as naming
inconsistencies, data type conflicts, redundancy and so on must be resolved.
c. Data Reduction: Obtains a reduced representation of the dataset that is much smaller in volume,
and yet produces same analytical results.
d. Data Transformation: Data is transformed or consolidated into formats appropriate for mining.


**What are the main tasks of data mining ?**
. Characterization
b. Discrimination
c. Association and Correlation Analysis
d. Classification
e. Prediction
f. Clustering
g. Outlier Analysis
h. Evolution Analysis


**What is data visualisation ?**

Data visualization is the presentation of data in a pictorial or graphical format. It enables decision makers to see analytics presented visually, so they can grasp difficult concepts or identify new patterns. With interactive visualization, you can take the concept a step further by using technology to drill down into charts and graphs for more detail, interactively changing what data you see and how it’s processed.

What is dat reduction ?

When we use histogram?

What is data normalisation ?

What is cleaning ?

**How to handle missing values in data ?**

Ignore the tuple
Fill the values manually
Use a global constant to fill the missing value
Use a measure of central tendency for the attribute.
Use the attribute mean or median for all samples belonging to the same class as the given tuple
Use the most probable value to fill in the missing value

What is data discretisation ?

What is binning ? 3 methods ? Why we do that ?

What is classification ?

**What is clustering ?**
Clustering analyzes data objects without consulting a known class label. The objects are clustered
or grouped based on the principle of maximizing the intraclass similarity and minimizing the interclass
similarity. Each cluster that is formed can be viewed as a class of objects. Clustering can also facilitate
taxonomy formation, that is, the organization of observations into a hierarchy of classes that group
similar events together.

What is frequent data mining ?

What are the applications of classification ?

What are the applications of clustering ?

What is association rules ?

What is apriory algorithms ?

What is decision tree algorithms ?

How we measure the performance of Classifiers ?

What's is info gain ?

What is naive based Classifier ?

**What is regression ?**

Regression is a statistical measure used in finance, investing and other disciplines that attempts to determine the strength of the relationship between one dependent variable (usually denoted by Y) and a series of other changing variables (known as independent variables). 


**What is multiple liner regression ?**

Multiple linear regression is the most common form of linear regression analysis.  As a predictive analysis, the multiple linear regression is used to explain the relationship between one continuous dependent variable and two or more independent variables.  The independent variables can be continuous or categorical (dummy coded as appropriate).

How to increase the classification accuracy ?


**What is random forest ?**

Random forests or random decision forests[1][2] are an ensemble learning method for classification, regression and other tasks, that operate by constructing a multitude of decision trees at training time and outputting the class that is the mode of the classes (classification) or mean prediction (regression) of the individual trees


**How K-means clustering algorithms works ?**

The Lloyd's algorithm, mostly known as k-means algorithm, is used to solve the k-means clustering problem and works as follows. 
    First, decide the number of clusters k. Then: 
         1.Initialize the center of the clusters.
         2.Attribute the closest cluster to each data point.
         3.Set the position of each cluster to the mean of all data points belonging to that cluster.
         4.Repeat steps 2-3 until convergence
         
         Deciding the number of clusters:
                The number of clusters should match the data. An incorrect choice of the number of clusters will invalidate the whole process. An empirical way to find the best number of clusters is to try K-means clustering with different number of clusters and measure the resulting sum of squares.

The most curious can look at this paper for a benchmarking of 30 procedures for estimating the number of clusters

What is k ?

What are the problems in k means clustering ?

What is hierarchical clustering algorithms ?

How to identify k efficiently ?

What are the problems in hierarchical clustering methods ?

Explain three methods of clustering ? How they work ?

**Explain three methods of clustering?**

Partitioning methods: 

-Given a databases of n objects or data tuples, a partitioning methods constructs k partitions of data, where each partition represents a cluster and k · n. Given k, the number of partitions to construct, it creates an initial partitioning. 

-It then uses an iterative relocation technique that attempts to improve the partitioning by moving objects from 
one group to another. The general criterion of a good partitioning is that objects in the same cluster are \close" or related to each other, whereas objects of di®erent clusters are \far apart". The k-means algorithm is a commonly used partitioning method.

Hierarchical methods: 

-A hierarchical method creates a hierarchical decomposition of the given set of data objects. It can be 
either agglomerative or divisive. The agglomerative (bottom-up) approach starts with each object forming a separate group. 

-It successively merges the objects that are close to one another, until all of the groups are merged into one, or until a termination condition holds. The divisive (top-down) approach starts with all of the objects in the same cluster. In each successive iteration, a cluster is split up into smaller clusters, until eventually each object forms its own cluster or until a termination condition holds. 

-AGNES and DIANA are examples of hierarchical clustering. BIRCH integrates hierarchical clustering with iterative (distance-based) relocation.

Density-based methods: 

-These methods are based on the notion of density. The main idea is to continue growing a given cluster as 
long as the density in its \neighborhood" exceeds some threshold. That is, for each data point within a given cluster, the neighborhood of a given radius has to contain at least a minimum number of points. 

-This method can be used to ¯lter out noise and discover clusters of arbitrary shape. DBSCAN and OPTICS are typical examples of density-based clustering.

Grid-based methods: 

-Such methods quantize the object space into a ¯nite number of cells that form a grid structure. All of the clustering operations are performed on the grid structure. 

-The main advantage of this approach is its fast processing time, which is typically independent of the number of data objects and dependent only on the number of cells in each dimension in the quantized space. 

-STING is an example of grid-based clustering.

Model-based methods: 

-This approach hypothesizes a model for each of the clusters and finds the best ¯t of the data to the given model. 

-A model-based algorithm may locate clusters by constructing a density function that re°ects the spatial distribution of the data points. 

-It also leads to a way of automatically determining the number of clusters based on standard statistics. It takes \noise" or outliers into account, therein contributing to the robustness of the approach. COBWEB and self-organizing feature maps are examples of model-based clustering.

Methods for high-dimensional data: High-dimensional data can typically have many irrelevant dimensions. As the dimensionality increases, the data usually become increasingly sparse because the data points are likely located in di®erent dimensional subspaces. 

The distance measurement between pairs of points become meaningless and the average density of points anywhere in the data is likely to be low.

Distance- and density-based clustering methods are therefore ine®ective for clustering high- dimensional data. Alternative approaches have been proposed, such as subspace clustering methods, which search for clusters in subspaces (or subsets of dimensions) of the data, rather than over the entire data space. CLIQUE and PROCLUS are examples of subspace clustering methods. 

Frequent pattern-based clustering is another clustering methodology, which extracts distinct frequent patterns among subsets of dimensions that occur frequently. pCluster is an example of frequent pattern-based clustering that groups objects based on their pattern similarity.

Constraint-based methods: 

-These perform clustering by incorporating user-speci¯ed or application oriented constraints. A constraint can express a user's expectation or describe \properties" of the desired clustering results, and provides an e®ective means for communicating with the clustering process. 

-Constraint-based methods are used in spatial clustering for clustering with obstacle objects (e.g., considering obstacles such as rivers and highways when planning the placement of automated banking machines) and user-constrained cluster analysis (e.g, considering speci¯c constraints regarding customer groups when determining the best location for a new service station, such as must serve at least 100 high-value customers").

-In addition, semi-supervised clustering employs, for example, pairwise constraints (such as pairs of instances labeled as belonging to the same or different clusters) in order to improve the quality of the resulting clustering.

What is supervised and unsupervised learning ?

Explain market bucket analysis ?

What is role of math models in BI ?

Can you tell me about ethics in data mining ?

Define decision support system ?

How data mining is used in retail industry ?
