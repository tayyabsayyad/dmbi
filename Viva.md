These are few questions which we normally ask in DBMI.

What is data mining ?

Data Mining is a computational process of discovering patterns in large data sets involving methods at the intersection of artificial intelligence, machine learning, statistics and database system.
Or it can be defined as 
Data mining is a process of discovering interesting patterns from huge amounts of data.


Is data mining a hype ?

What is Machine Learning ?
It is subfield of comuter science that focuses on getting computer to act without being explicitly programmed.It focuses on the development of computer program that can change when exposed to new data.

What is data preprocessing ?

Why we need to to preprocess the data ?

What is consequence of having a data outliers ?
An outliers is a value that is very different from the other data in your data set.This can skew your results.

What is outlier ?
An outliers is a data object in a data set that deviates significantly from the rest of the data object, as if it were generated by a different mechanism

What are different methods of detecting outliers ?

Are their any applications detecting of outliers ?

What is data exploration ?

Can you draw box plot of given data ?

What is five number summary ?

What are the data mining applications ?

Can you explain how data mining is used in droid detection ?

Explain data mining applications for the finance ?

Explain data mining application for CRM ?

Explain how data mining can be used in medical industry ?

Explain data preprocessing steps ?
. Data Cleaning: Clean the data by filling in missing values, smoothening noisy data, identifying and
removing outliers and inconsistencies.
b. Data Integration: Data analysis involves integrating multiple databases, data cubes or files to
obtain consolidated data. Before any data is used, integration problems such as naming
inconsistencies, data type conflicts, redundancy and so on must be resolved.
c. Data Reduction: Obtains a reduced representation of the dataset that is much smaller in volume,
and yet produces same analytical results.
d. Data Transformation: Data is transformed or consolidated into formats appropriate for mining.


What are the main tasks of data mining ?
. Characterization
b. Discrimination
c. Association and Correlation Analysis
d. Classification
e. Prediction
f. Clustering
g. Outlier Analysis
h. Evolution Analysis


What is data visualisation ?

What is dat reduction ?

When we use histogram?

What is data normalisation ?

What is cleaning ?

How to handle missing values in data ?

What is data discretisation ?

What is binning ? 3 methods ? Why we do that ?

What is classification ?

What is clustering ?
Clustering analyzes data objects without consulting a known class label. The objects are clustered
or grouped based on the principle of maximizing the intraclass similarity and minimizing the interclass
similarity. Each cluster that is formed can be viewed as a class of objects. Clustering can also facilitate
taxonomy formation, that is, the organization of observations into a hierarchy of classes that group
similar events together.

What is frequent data mining ?

What are the applications of classification ?

What are the applications of clustering ?

What is association rules ?

What is apriory algorithms ?

What is decision tree algorithms ?

How we measure the performance of Classifiers ?

What's is info gain ?

What is naive based Classifier ?

What is regression ?

What is multiple liner regression ?

How to increase the classification accuracy ?

What is random forest ?
Random forests or random decision forests[1][2] are an ensemble learning method for classification, regression and other tasks, that operate by constructing a multitude of decision trees at training time and outputting the class that is the mode of the classes (classification) or mean prediction (regression) of the individual trees

How K-means clustering algorithms works ?

What is k ?

What are the problems in k means clustering ?

What is hierarchical clustering algorithms ?

How to identify k efficiently ?

What are the problems in hierarchical clustering methods ?

Explain three methods of clustering ? How they work ?
Explain three methods of clustering?

Partitioning methods: Given a databases of n objects or data tuples, a partitioning methods constructs k partitions of data, 
where each partition represents a cluster and k · n. Given k, the number of partitions to construct, it creates an initial 
partitioning. It then uses an iterative relocation technique that attempts to improve the partitioning by moving objects from 
one group to another. The general criterion of a good partitioning is that objects in the same cluster are \close" or related 
to each other, whereas objects of di®erent clusters are \far apart". The k-means algorithm is a commonly used partitioning method.

Hierarchical methods: A hierarchical method creates a hierarchical decomposition of the given set of data objects. It can be 
either agglomerative or divisive. The agglomerative (bottom-up) approach starts with each object forming a separate group. 
It successively merges the objects that are close to one another, until all of the groups are merged into one, or until a termination 
condition holds. The divisive (top-down) approach starts with all of the objects in the same cluster. In each successive iteration, a 
cluster is split up into smaller clusters, until eventually each object forms its own cluster or until a termination condition holds. 
AGNES and DIANA are examples of hierarchical clustering. BIRCH integrates hierarchical clustering with iterative (distance-based) 
relocation.

Density-based methods: These methods are based on the notion of density. The main idea is to continue growing a given cluster as 
long as the density in its \neighborhood" exceeds some threshold. That is, for each data point within a given cluster, the neighborhood 
of a given radius has to contain at least a minimum number of points. This method can be used to ¯lter out noise and discover clusters 
of arbitrary shape. DBSCAN and OPTICS are typical examples of density-based clustering.

Grid-based methods: Such methods quantize the object space into a ¯nite number of cells that form a grid structure. All of the 
clustering operations are performed on the grid structure. The main advantage of this approach is its fast processing time, 
which is typically independent of the number of data objects and dependent only on the number of cells in each dimension in the 
quantized space. STING is an example of grid-based clustering.

Model-based methods: This approach hypothesizes a model for each of the clusters and finds the best ¯t of the data to the given model. 
A model-based algorithm may locate clusters by constructing a density function that re°ects the spatial distribution of the data points. 
It also leads to a way of automatically determining the number of clusters based on standard statistics. It takes \noise" or outliers 
into account, therein contributing to the robustness of the approach. COBWEB and self-organizing feature maps are examples of 
model-based clustering.

Methods for high-dimensional data: High-dimensional data can typically have many irrelevant dimensions. As the dimensionality increases, 
the data usually become increasingly sparse because the data points are likely located in di®erent dimensional subspaces. The distance 
measurement between pairs of points become meaningless and the average density of points anywhere in the data is likely to be low.
Distance- and density-based clustering methods are therefore ine®ective for clustering high- dimensional data. Alternative approaches 
have been proposed, such as subspace clustering methods, which search for clusters in subspaces (or subsets of dimensions) of the data, 
rather than over the entire data space. CLIQUE and PROCLUS are examples of subspace clustering methods. Frequent pattern-based 
clustering is another clustering methodology, which extracts distinct frequent patterns among subsets of dimensions that occur 
frequently. pCluster is an example of frequent pattern-based clustering that groups objects based on their pattern similarity.

Constraint-based methods: These perform clustering by incorporating user-speci¯ed or application oriented constraints. A constraint 
can express a user's expectation or describe \properties" of the desired clustering results, and provides an e®ective means for 
communicating with the clustering process. Constraint-based methods are used in spatial clustering for clustering with obstacle 
objects (e.g., considering obstacles such as rivers and highways when planning the placement of automated banking machines) and 
user-constrained cluster analysis (e.g, considering speci¯c constraints regarding customer groups when determining the best 
location for a new service station, such as ``must serve at least 100 high-value customers"). In addition, semi-supervised 
clustering employs, for example, pairwise constraints (such as pairs of instances labeled as belonging to the same or different 
clusters) in order to improve the quality of the resulting clustering.

What is supervised and unsupervised learning ?

Explain market bucket analysis ?

What is role of math models in BI ?

Can you tell me about ethics in data mining ?

Define decision support system ?

How data mining is used in retail industry ?
