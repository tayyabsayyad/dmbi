**1.Use Apriori algorithm to identify the frequent item-set in the following database. Then extract the strong association rules from these sets**

Min Support = 30.  Min Confidence = 75 %

 ![Table_7.1.png](/Images/Table_7.1.png)



2. Explain Multilevel association rules with suitable example 


MULTILEVEL ASSOCIATION RULES:

- Association rules generated from mining data at multiple levels of abstraction are called multiple-level or multilevel association rules.
- Multilevel association rules can be mined efficiently using concept hierarchies under a support-confidence framework.
- Rules at high concept level may add to common sense while rules at low concept level may not be useful always.

* Using uniform minimum support for all levels:
- When a uniform minimum support threshold is used, the search procedure is simplified.
- The method is also simple, in that users are required to specify only one minimum support threshold.
- The same minimum support threshold is used when mining at each level of abstraction.

For example, in Figure, a minimum support threshold of 5% is used throughout.
(e.g. for mining from “computer” down to “laptop computer”).
Both “computer” and “laptop computer” are found to be frequent, while “desktop computer” is not.

Using reduced minimum support at lower levels:

Each level of abstraction has its own minimum support threshold.
The deeper the level of abstraction, the smaller the corresponding threshold is.
For example in Figure, the minimum support thresholds for levels 1 and 2 are 5% and 3%, respectively.
In this way, “computer,” “laptop computer,” and “desktop computer” are all considered frequent.
Multilevel Association rule consists of alternate search strategies and Controlled level cross filtering:

1.Alternate Search Strategies:

Level by level independent:

Full breadth search.
No background knowledge in pruning.
Leads to examine lot of infrequent items.
Level-cross filtering by single item:

Examine nodes at level i only if node at level (i-1) is frequent.
Misses frequent items at lower level abstractions (due to reduced support).
Level-cross filtering by k-item set:
Examine k-itemsets at level i only if k-itemsets at level (i-1) is frequent.
Misses frequent k-itemsets at lower level abstractions (due to reduced support).
Controlled Level-cross filtering by single item:
A modified level-cross filtering by single item.
Sets a level passage threshold for every level.
Allows the inspection of lower abstractions even if its ancestor fails to satisfy min_sup threshold.



3. Explain sequence mining in the transactional database.



Sequential pattern mining is trying to find relationships between occurrences of sequential events, to find if there exists any specific order of the occurrences.
We can find the sequential patterns of specific individual items also we can find the sequential patterns across different items.
Application:

Sequential pattern mining is widely used in analyzing of DNA sequence.
Sequential pattern can be widely used in different areas, such as mining user access patterns for the web sites, using the history of symptoms to predict certain kind of disease, also by using sequential pattern mining, the retailers can make the inventory control more efficient.
Challenges on Sequential pattern mining:

A huge number of possible sequential patterns are hidden in databases.
A mining algorithm should find the complete set of patterns, be highly efficient, scalable.
Example:

Consider the database shown in fig 1 (This database has been sorted on customer-id and transaction-time) fig 2 shows this database expressed as a set of customer sequences.

With minimum support set to 25%, i.e. a minimum support of 2 customers, two sequences :< ( 30) (90)> and < (30) (40 70)> are maximal among those satisfying the support constraint, and are desired sequential patterns.

The sequential pattern < (30) (90)> is supported by customers 1 and 4.Customer 4 buys items (40 70) in between items 30 and 90, but supports the pattern < (30) (90)> since we are looking for patterns that are not necessarily contiguous. The sequential pattern <30((40 70)> is supported by customers 2 and 4. Customer 2 buys 60 along with 40 and 70, but supports this pattern since (40 70) is a subset of (40 60 70).

An example of a sequence that does not have minimum support is the sequence < (10 20)(30)>, which is only supported by customers 2. The sequences <(30)>,<(40)>.<(70)>,<(90)>,<(30)(40)>,<(30)(70)>and <(40)(70)>, though having minimum support, are not in the answer because they are not maximal.

Customer Id	Transaction Time	Items Bought
1               June 25’93              30
1               June 30’93              90

2               June 10’93              10,20
2               June 15’93              30
2               June 20’93              40,60,70

3               June 25’93	        30,50,70

4               June 25’93              30
4               June 30’93              40,70
4               June 25’93              90

5               June 12’93              90


Fig1: Database Sorted by Customer Id and Transaction Time


Customer Id	Customer Sequence
1               < (30) (90)>
2               < (10 20)(30) (40 60 70)>
3               <(30,50,70)>
4               <(30)(40,70)(90)>
5               <(90)>

Fig2: Customer Sequence Version of the Database


Sequential Patterns with support >25%
< (30) (90)>
<(30)(40,70)>

Fig3: The answer set
Scalable Methods for Mining Sequential Patterns:

Apriori-based Approaches:
GSP: (A sequential Pattern Mining Algorithm Based on Candidate Generate and Test) It integrates with time constraints and relaxes the definition of transaction; also consider the knowledge of taxonomies.

SPADE: (Sequential Pattern Discovery using Equivalent Class) SPADE is an algorithm proposed to find frequent sequences using efficient lattice search techniques and simple joins.

Pattern –Growth –based Approaches:
PrefixSpan :( Mining Sequential Patterns by Prefix Projections) It mainly employs the method of database projection to make the database projection to make the database for next pass much smaller and consequently make the algorithm more speedy.



4. Consider the following transaction database.

TID	ITEMS
01,	A,B,C,D
02, 	A,B,C,D,E,G
03,	A,C,G,H,K
04,	B,C,D,E,K
05	D,E,F,H,L
06	A,B,C,D,L	
07	B,I,E,K,L
08	A,B,D,E,K
09	A,E,F,H,L
10	B,C,D,F

Apply apriory algorithm with the minimum support of 30% and minimum confidance of 70% and find all the accociation rules in the database.

	
